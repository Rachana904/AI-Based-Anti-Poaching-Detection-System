{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split # Needed in Block 2\n",
        "\n",
        "# --- 1. CONFIGURATION: Verified Paths ---\n",
        "\n",
        "# ⚠️ This is the FINAL CORRECTED ROOT PATH based on your diagnostic output.\n",
        "DRIVE_DATA_ROOT = \"/content/drive/MyDrive/weapon detection dataset for YOLOv5/dataset/dataset\"\n",
        "\n",
        "# Define the local temporary training path (DO NOT CHANGE)\n",
        "BASE_DIR = \"/content/YOLO_AntiPoaching_Train\"\n",
        "YAML_PATH = f\"{BASE_DIR}/poaching_config.yaml\"\n",
        "print(f\"Working Directory: {BASE_DIR}\")\n",
        "\n",
        "\n",
        "# --- 2. INSTALLATION AND MOUNT ---\n",
        "drive.mount('/content/drive')\n",
        "! pip install ultralytics # Installs YOLOv8\n",
        "\n",
        "# Clean and create local folders\n",
        "! rm -rf $BASE_DIR\n",
        "! mkdir -p $BASE_DIR/images $BASE_DIR/labels\n",
        "\n",
        "# --- 3. COPY AND REMAP DATA ---\n",
        "\n",
        "# Source folders are relative to DRIVE_DATA_ROOT\n",
        "IMAGES_SOURCE_DIR = f\"{DRIVE_DATA_ROOT}/images\"\n",
        "LABELS_SOURCE_DIR = f\"{DRIVE_DATA_ROOT}/labels\"\n",
        "print(f\"\\nDiscovered Image Source: {IMAGES_SOURCE_DIR}\")\n",
        "print(f\"Discovered Label Source: {LABELS_SOURCE_DIR}\")\n",
        "\n",
        "\n",
        "# 1. Copy All Images (Recursively searches train/val/etc. subfolders)\n",
        "print(\"\\nStarting Image Copy to local storage...\")\n",
        "! cp -r \"$IMAGES_SOURCE_DIR\"/*/* $BASE_DIR/images/  # Copies all files from train/, val/ subfolders\n",
        "print(f\"Total images copied locally: {len(os.listdir(f'{BASE_DIR}/images'))}\")\n",
        "\n",
        "\n",
        "# 2. CRITICAL STEP: REMAP LABELS to ID 1 (Weapon_Tool) and copy locally\n",
        "count_remapped_labels = 0\n",
        "for root, _, filenames in os.walk(LABELS_SOURCE_DIR):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('.txt'):\n",
        "            source_filepath = os.path.join(root, filename)\n",
        "            destination_filepath = os.path.join(BASE_DIR, 'labels', filename)\n",
        "\n",
        "            with open(source_filepath, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            with open(destination_filepath, 'w') as f:\n",
        "                for line in lines:\n",
        "                    parts = line.strip().split()\n",
        "                    if parts:\n",
        "                        # Unify all weapon-related classes (IDs 0, 1, etc.) to the new ID 1.\n",
        "                        parts[0] = '1'\n",
        "                        f.write(' '.join(parts) + '\\n')\n",
        "                        count_remapped_labels += 1\n",
        "\n",
        "print(f\"\\nLabels Processed and Remapped to Class ID 1: {count_remapped_labels}\")\n",
        "print(\"--- Block 1 Execution Complete: Data Ready ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k1HX25U6_NBM",
        "outputId": "f198bb53-b285-4648-80c0-0504f5c85f24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working Directory: /content/YOLO_AntiPoaching_Train\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.209)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.17)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "\n",
            "Discovered Image Source: /content/drive/MyDrive/weapon detection dataset for YOLOv5/dataset/dataset/images\n",
            "Discovered Label Source: /content/drive/MyDrive/weapon detection dataset for YOLOv5/dataset/dataset/labels\n",
            "\n",
            "Starting Image Copy to local storage...\n",
            "Total images copied locally: 4156\n",
            "\n",
            "Labels Processed and Remapped to Class ID 1: 4651\n",
            "--- Block 1 Execution Complete: Data Ready ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from sklearn.model_selection import train_test_split # Ensure this is installed\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# Define paths (re-using variables from Block 1)\n",
        "BASE_DIR = \"/content/YOLO_AntiPoaching_Train\"\n",
        "YAML_PATH = f\"{BASE_DIR}/poaching_config.yaml\"\n",
        "print(f\"Configuration file path: {YAML_PATH}\")\n",
        "\n",
        "# 1. Prepare for file splitting\n",
        "all_image_paths = glob.glob(f\"{BASE_DIR}/images/*.jpg\") # Get all images for splitting\n",
        "\n",
        "# Create split directories (train/val/test) inside the BASE_DIR\n",
        "for split in ['train', 'val', 'test']:\n",
        "    os.makedirs(f\"{BASE_DIR}/{split}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"{BASE_DIR}/{split}/labels\", exist_ok=True)\n",
        "\n",
        "\n",
        "# 2. Perform the dataset split (70% Train / 20% Val / 10% Test)\n",
        "print(\"\\nSplitting dataset into train/val/test folders (70/20/10)...\")\n",
        "\n",
        "train_ratio, val_ratio = 0.7, 0.2\n",
        "test_ratio = 1.0 - train_ratio - val_ratio\n",
        "\n",
        "# Split filenames (without extensions)\n",
        "base_names = [os.path.basename(p).split('.')[0] for p in all_image_paths]\n",
        "train_names, test_names = train_test_split(base_names, test_size=test_ratio, random_state=42)\n",
        "train_names, val_names = train_test_split(train_names, test_size=val_ratio/(train_ratio), random_state=42)\n",
        "\n",
        "def move_split(file_names, split_name):\n",
        "    \"\"\"Moves the images AND their corresponding label files.\"\"\"\n",
        "    for name in file_names:\n",
        "        # Move image\n",
        "        shutil.move(f\"{BASE_DIR}/images/{name}.jpg\", f\"{BASE_DIR}/{split_name}/images/{name}.jpg\")\n",
        "        # Move corresponding label\n",
        "        shutil.move(f\"{BASE_DIR}/labels/{name}.txt\", f\"{BASE_DIR}/{split_name}/labels/{name}.txt\")\n",
        "\n",
        "move_split(train_names, 'train')\n",
        "move_split(val_names, 'val')\n",
        "move_split(test_names, 'test')\n",
        "\n",
        "print(f\"Dataset split successful. Train: {len(train_names)}, Val: {len(val_names)}, Test: {len(test_names)}\")\n",
        "\n",
        "\n",
        "# 3. Define final YAML configuration content\n",
        "yaml_content = f\"\"\"\n",
        "path: {BASE_DIR}\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "nc: 3\n",
        "names: ['Human', 'Weapon_Tool', 'Animal_Vehicle_Background']\n",
        "\"\"\"\n",
        "with open(YAML_PATH, 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "\n",
        "# 4. Download YOLOv8m and Start Training\n",
        "! wget -q https://github.com/ultralytics/assets/releases/download/v8.2.24/yolov8m.pt\n",
        "\n",
        "print(\"\\nStarting YOLOv8 Medium Fine-Tuning. Estimated completion: ~3-4 hours.\")\n",
        "\n",
        "! yolo task=detect mode=train \\\n",
        "    model=yolov8m.pt \\\n",
        "    data={YAML_PATH} \\\n",
        "    epochs=30 \\\n",
        "    imgsz=640 \\\n",
        "    batch=8 \\\n",
        "    name=AntiPoaching_QuickModel_Final\n",
        "\n",
        "print(\"\\n--- Block 2 Execution Complete: TRAINING LAUNCHED ---\")\n",
        "print(\"You must wait for the cell to finish (or time out) before the next step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oOk_ULTnCIDX",
        "outputId": "88aa5e2c-babe-469c-cbf9-4762fdf9bde5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration file path: /content/YOLO_AntiPoaching_Train/poaching_config.yaml\n",
            "\n",
            "Splitting dataset into train/val/test folders (70/20/10)...\n",
            "Dataset split successful. Train: 2671, Val: 1069, Test: 416\n",
            "\n",
            "Starting YOLOv8 Medium Fine-Tuning. Estimated completion: ~3-4 hours.\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100% ━━━━━━━━━━━━ 49.7MB 261.2MB/s 0.2s\n",
            "Ultralytics 8.3.209 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/YOLO_AntiPoaching_Train/poaching_config.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=AntiPoaching_QuickModel_Final, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/AntiPoaching_QuickModel_Final, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 204.4MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3777433  ultralytics.nn.modules.head.Detect           [3, [192, 384, 576]]          \n",
            "Model summary: 169 layers, 25,858,057 parameters, 25,858,041 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 284.7MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1375.0±752.9 MB/s, size: 52.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/YOLO_AntiPoaching_Train/train/labels... 2671 images, 2 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2671/2671 2.5Kit/s 1.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/YOLO_AntiPoaching_Train/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 720.4±439.5 MB/s, size: 42.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/YOLO_AntiPoaching_Train/val/labels... 1069 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1069/1069 1.2Kit/s 0.9s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/YOLO_AntiPoaching_Train/val/labels.cache\n",
            "Plotting labels to /content/runs/detect/AntiPoaching_QuickModel_Final/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/AntiPoaching_QuickModel_Final\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30       3.3G      1.455      2.068      1.719         15        640: 100% ━━━━━━━━━━━━ 334/334 3.4it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.3it/s 15.6s\n",
            "                   all       1069       1181      0.435      0.257       0.26      0.132\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      4.84G      1.683      2.137      1.924         10        640: 100% ━━━━━━━━━━━━ 334/334 3.4it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.0s\n",
            "                   all       1069       1181      0.517      0.274      0.271      0.135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      4.91G      1.677      2.084      1.907         16        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.2s\n",
            "                   all       1069       1181      0.567      0.296      0.352      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      4.97G      1.598      1.975      1.853         18        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.0s\n",
            "                   all       1069       1181      0.582      0.364      0.419      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      5.04G      1.481      1.831      1.742         22        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.0s\n",
            "                   all       1069       1181      0.675      0.419      0.508      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      5.11G      1.442      1.734      1.709         13        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.1s\n",
            "                   all       1069       1181      0.595      0.442      0.509      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      5.18G      1.386      1.702      1.678         14        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.1s\n",
            "                   all       1069       1181      0.747      0.448       0.56       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      5.24G      1.367      1.607      1.669         20        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.0s\n",
            "                   all       1069       1181      0.605      0.482      0.543      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      5.31G      1.321      1.553      1.618         13        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 13.9s\n",
            "                   all       1069       1181      0.656      0.528      0.597      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      5.37G      1.281      1.481       1.59         25        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 13.9s\n",
            "                   all       1069       1181      0.659      0.531      0.606      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      5.44G      1.281      1.426      1.595         22        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.2s\n",
            "                   all       1069       1181      0.684      0.486      0.588      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      5.51G      1.257      1.425      1.571         18        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.2s\n",
            "                   all       1069       1181      0.667      0.553      0.626       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      5.57G      1.234      1.379      1.557         18        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.2s\n",
            "                   all       1069       1181      0.654      0.528      0.611      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      5.64G      1.221      1.361      1.538         17        640: 100% ━━━━━━━━━━━━ 334/334 3.4it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.6it/s 14.4s\n",
            "                   all       1069       1181      0.684      0.555      0.648      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      5.71G      1.186       1.29      1.509         14        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.0s\n",
            "                   all       1069       1181      0.694      0.557      0.657      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      5.77G      1.174      1.263        1.5         21        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.0s\n",
            "                   all       1069       1181       0.69      0.574      0.665      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      6.08G      1.123      1.202      1.459         14        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.5it/s 15.1s\n",
            "                   all       1069       1181      0.695      0.543      0.662      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      6.15G      1.139      1.202      1.464         14        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.1s\n",
            "                   all       1069       1181       0.68      0.581      0.669       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      6.22G       1.14      1.203      1.462         17        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:37\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.1s\n",
            "                   all       1069       1181      0.718      0.597      0.699      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      6.29G      1.106      1.168      1.448         18        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.2s\n",
            "                   all       1069       1181      0.691      0.592      0.703      0.462\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      6.35G      1.205      1.162      1.565          7        640: 100% ━━━━━━━━━━━━ 334/334 3.4it/s 1:38\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.9it/s 13.8s\n",
            "                   all       1069       1181      0.674      0.622      0.714       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      6.42G      1.187      1.084      1.553          7        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.0s\n",
            "                   all       1069       1181      0.687      0.627       0.71      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      6.68G      1.148       1.04      1.531          7        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.2s\n",
            "                   all       1069       1181      0.735      0.624      0.728      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      7.19G       1.13     0.9967      1.502          7        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.1s\n",
            "                   all       1069       1181      0.683      0.647       0.73      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      7.26G      1.111     0.9766      1.484          9        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 13.9s\n",
            "                   all       1069       1181      0.718       0.66      0.745      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      7.33G      1.086     0.9443      1.461          8        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 13.9s\n",
            "                   all       1069       1181      0.712      0.658       0.74       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      7.39G      1.052     0.8961      1.431          7        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.9it/s 13.8s\n",
            "                   all       1069       1181      0.708      0.687      0.751      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      4.45G      1.035     0.8655       1.41          9        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 14.1s\n",
            "                   all       1069       1181      0.706      0.699      0.758      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      4.45G      1.023     0.8446      1.406          7        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.8it/s 13.9s\n",
            "                   all       1069       1181      0.719       0.71       0.76       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      4.45G     0.9924     0.8074      1.383          7        640: 100% ━━━━━━━━━━━━ 334/334 3.5it/s 1:36\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.7it/s 14.2s\n",
            "                   all       1069       1181      0.727       0.71      0.766      0.511\n",
            "\n",
            "30 epochs completed in 0.952 hours.\n",
            "Optimizer stripped from /content/runs/detect/AntiPoaching_QuickModel_Final/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from /content/runs/detect/AntiPoaching_QuickModel_Final/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating /content/runs/detect/AntiPoaching_QuickModel_Final/weights/best.pt...\n",
            "Ultralytics 8.3.209 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 92 layers, 25,841,497 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 67/67 4.6it/s 14.7s\n",
            "                   all       1069       1181      0.725      0.711      0.765      0.511\n",
            "           Weapon_Tool       1069       1181      0.725      0.711      0.765      0.511\n",
            "Speed: 0.2ms preprocess, 9.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/AntiPoaching_QuickModel_Final\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n",
            "\n",
            "--- Block 2 Execution Complete: TRAINING LAUNCHED ---\n",
            "You must wait for the cell to finish (or time out) before the next step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define paths\n",
        "TRAINED_MODEL_PATH=\"/content/runs/detect/AntiPoaching_QuickModel_Final/weights/best.pt\"\n",
        "ONNX_EXPORT_PATH=\"/content/runs/detect/AntiPoaching_QuickModel_Final/weights/best.onnx\"\n",
        "# ⚠️ UPDATE THIS DRIVE PATH to ensure you save the file correctly\n",
        "DRIVE_SAVE_PATH=\"/content/drive/MyDrive/Final_AntiPoaching_Model_V1.onnx\"\n",
        "\n",
        "# 2. Export the model to ONNX format (Essential for fast backend deployment)\n",
        "print(\"Starting ONNX Export...\")\n",
        "! yolo export model=$TRAINED_MODEL_PATH format=onnx\n",
        "\n",
        "# 3. Copy the final ONNX model to Google Drive (for persistence)\n",
        "! cp $ONNX_EXPORT_PATH \"$DRIVE_SAVE_PATH\"\n",
        "\n",
        "print(f\"\\n--- Model Export and Save Complete ---\")\n",
        "print(f\"Final Model saved permanently to Drive: {DRIVE_SAVE_PATH}\")\n",
        "print(\"You now have the core AI asset for deployment.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZQ24N2iQXMI",
        "outputId": "f6bda567-6263-435c-c461-c634ba47c02a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting ONNX Export...\n",
            "Ultralytics 8.3.209 🚀 Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "💡 ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "Model summary (fused): 92 layers, 25,841,497 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/AntiPoaching_QuickModel_Final/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (49.6 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 2.3s\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.71...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 5.8s, saved as '/content/runs/detect/AntiPoaching_QuickModel_Final/weights/best.onnx' (98.8 MB)\n",
            "\n",
            "Export complete (8.3s)\n",
            "Results saved to \u001b[1m/content/runs/detect/AntiPoaching_QuickModel_Final/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/detect/AntiPoaching_QuickModel_Final/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/runs/detect/AntiPoaching_QuickModel_Final/weights/best.onnx imgsz=640 data=/content/YOLO_AntiPoaching_Train/poaching_config.yaml  \n",
            "Visualize:       https://netron.app\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/export\n",
            "\n",
            "--- Model Export and Save Complete ---\n",
            "Final Model saved permanently to Drive: /content/drive/MyDrive/Final_AntiPoaching_Model_V1.onnx\n",
            "You now have the core AI asset for deployment.\n"
          ]
        }
      ]
    }
  ]
}